{
    "benchmarks": [
        {
            "timestamp": "2025-04-15_11-29-46",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 597.1,
            "std_ttft_ms": 53.45,
            "mean_tpot_ms": 88.2,
            "std_tpot_ms": 3.24,
            "mean_tps": 11.34,
            "std_tps": 0.4,
            "tps_decode_throughput": 11.3,
            "tps_prefill_throughput": 214.4,
            "mean_e2el_ms": 11800.2,
            "request_throughput": 0.085,
            "total_input_tokens": 1024,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-29-46_isl-128_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_11-31-48",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 1,
            "mean_ttft_ms": 944.2,
            "std_ttft_ms": 55.85,
            "mean_tpot_ms": 90.4,
            "std_tpot_ms": 0.79,
            "mean_tps": 11.06,
            "std_tps": 0.1,
            "tps_decode_throughput": 11.1,
            "tps_prefill_throughput": 135.6,
            "mean_e2el_ms": 93423.7,
            "request_throughput": 0.011,
            "total_input_tokens": 512,
            "total_output_tokens": 4096,
            "num_prompts": 4,
            "num_requests": 4,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-31-48_isl-128_osl-1024_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-04-15_11-39-42",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 1024,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 1623.7,
            "std_ttft_ms": 120.72,
            "mean_tpot_ms": 90.4,
            "std_tpot_ms": 2.14,
            "mean_tps": 11.06,
            "std_tps": 0.26,
            "tps_decode_throughput": 11.1,
            "tps_prefill_throughput": 630.7,
            "mean_e2el_ms": 13107.7,
            "request_throughput": 0.076,
            "total_input_tokens": 8192,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-39-42_isl-1024_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_11-41-47",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 2259.0,
            "std_ttft_ms": 10.35,
            "mean_tpot_ms": 94.1,
            "std_tpot_ms": 2.14,
            "mean_tps": 10.63,
            "std_tps": 0.24,
            "tps_decode_throughput": 10.6,
            "tps_prefill_throughput": 906.6,
            "mean_e2el_ms": 14208.3,
            "request_throughput": 0.07,
            "total_input_tokens": 16384,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-41-47_isl-2048_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_11-44-02",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3072,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 3008.0,
            "std_ttft_ms": 105.22,
            "mean_tpot_ms": 101.0,
            "std_tpot_ms": 2.09,
            "mean_tps": 9.9,
            "std_tps": 0.2,
            "tps_decode_throughput": 9.9,
            "tps_prefill_throughput": 1021.3,
            "mean_e2el_ms": 15839.7,
            "request_throughput": 0.063,
            "total_input_tokens": 24576,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-44-02_isl-3072_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_11-46-30",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4096,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 3711.1,
            "std_ttft_ms": 94.36,
            "mean_tpot_ms": 103.0,
            "std_tpot_ms": 3.07,
            "mean_tps": 9.71,
            "std_tps": 0.28,
            "tps_decode_throughput": 9.7,
            "tps_prefill_throughput": 1103.7,
            "mean_e2el_ms": 16786.7,
            "request_throughput": 0.06,
            "total_input_tokens": 32768,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-46-30_isl-4096_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_11-49-07",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8192,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 6906.9,
            "std_ttft_ms": 141.77,
            "mean_tpot_ms": 119.0,
            "std_tpot_ms": 2.59,
            "mean_tps": 8.4,
            "std_tps": 0.18,
            "tps_decode_throughput": 8.4,
            "tps_prefill_throughput": 1186.1,
            "mean_e2el_ms": 22020.4,
            "request_throughput": 0.045,
            "total_input_tokens": 65536,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-49-07_isl-8192_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_11-52-38",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16384,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 13950.8,
            "std_ttft_ms": 158.67,
            "mean_tpot_ms": 148.2,
            "std_tpot_ms": 2.53,
            "mean_tps": 6.75,
            "std_tps": 0.11,
            "tps_decode_throughput": 6.7,
            "tps_prefill_throughput": 1174.4,
            "mean_e2el_ms": 32771.0,
            "request_throughput": 0.031,
            "total_input_tokens": 131072,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-52-38_isl-16384_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_11-57-46",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 32000,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 30150.3,
            "std_ttft_ms": 2620.53,
            "mean_tpot_ms": 205.3,
            "std_tpot_ms": 2.68,
            "mean_tps": 4.87,
            "std_tps": 0.06,
            "tps_decode_throughput": 4.9,
            "tps_prefill_throughput": 1061.3,
            "mean_e2el_ms": 56229.2,
            "request_throughput": 0.018,
            "total_input_tokens": 256000,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_11-57-46_isl-32000_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_12-06-21",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 32,
            "mean_ttft_ms": 12698.5,
            "std_ttft_ms": 1595.53,
            "mean_tpot_ms": 100.0,
            "std_tpot_ms": 1.21,
            "mean_tps": 10.0,
            "std_tps": 0.12,
            "tps_decode_throughput": 319.9,
            "tps_prefill_throughput": 322.6,
            "mean_e2el_ms": 25404.2,
            "request_throughput": 1.258,
            "total_input_tokens": 32768,
            "total_output_tokens": 32768,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_12-06-21_isl-128_osl-128_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_12-10-02",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 32,
            "mean_ttft_ms": 12240.6,
            "std_ttft_ms": 606.53,
            "mean_tpot_ms": 100.8,
            "std_tpot_ms": 1.36,
            "mean_tps": 9.92,
            "std_tps": 0.13,
            "tps_decode_throughput": 317.5,
            "tps_prefill_throughput": 334.6,
            "mean_e2el_ms": 115343.3,
            "request_throughput": 0.277,
            "total_input_tokens": 16384,
            "total_output_tokens": 131072,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_12-10-02_isl-128_osl-1024_maxcon-32_n-128.json"
        },
        {
            "timestamp": "2025-04-15_12-19-25",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 32,
            "mean_ttft_ms": 64079.0,
            "std_ttft_ms": 275.0,
            "mean_tpot_ms": 104.5,
            "std_tpot_ms": 2.7,
            "mean_tps": 9.57,
            "std_tps": 0.24,
            "tps_decode_throughput": 306.2,
            "tps_prefill_throughput": 1022.7,
            "mean_e2el_ms": 77349.3,
            "request_throughput": 0.414,
            "total_input_tokens": 524288,
            "total_output_tokens": 32768,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_12-19-25_isl-2048_osl-128_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_12-30-05",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 2048,
            "max_con": 32,
            "mean_ttft_ms": 63096.5,
            "std_ttft_ms": 7650.18,
            "mean_tpot_ms": 112.5,
            "std_tpot_ms": 4.74,
            "mean_tps": 8.89,
            "std_tps": 0.36,
            "tps_decode_throughput": 284.6,
            "tps_prefill_throughput": 1038.7,
            "mean_e2el_ms": 293285.4,
            "request_throughput": 0.105,
            "total_input_tokens": 131072,
            "total_output_tokens": 131072,
            "num_prompts": 64,
            "num_requests": 64,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_12-30-05_isl-2048_osl-2048_maxcon-32_n-64.json"
        },
        {
            "timestamp": "2025-04-15_12-43-56",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 86055.7,
            "std_ttft_ms": 536.55,
            "mean_tpot_ms": 107.8,
            "std_tpot_ms": 3.25,
            "mean_tps": 9.27,
            "std_tps": 0.27,
            "tps_decode_throughput": 296.8,
            "tps_prefill_throughput": 1115.6,
            "mean_e2el_ms": 92848.4,
            "request_throughput": 0.345,
            "total_input_tokens": 768000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_12-43-56_isl-3000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_12-56-35",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 105206.5,
            "std_ttft_ms": 22458.05,
            "mean_tpot_ms": 146.4,
            "std_tpot_ms": 211.42,
            "mean_tps": 6.83,
            "std_tps": 4.04,
            "tps_decode_throughput": 218.6,
            "tps_prefill_throughput": 1216.7,
            "mean_e2el_ms": 114429.3,
            "request_throughput": 0.27,
            "total_input_tokens": 1024000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_12-56-35_isl-4000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_13-12-39",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4500,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 107664.4,
            "std_ttft_ms": 38006.35,
            "mean_tpot_ms": 112.9,
            "std_tpot_ms": 2.45,
            "mean_tps": 8.86,
            "std_tps": 0.19,
            "tps_decode_throughput": 283.5,
            "tps_prefill_throughput": 1337.5,
            "mean_e2el_ms": 114776.2,
            "request_throughput": 0.27,
            "total_input_tokens": 1152000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_13-12-39_isl-4500_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_13-28-47",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 209052.4,
            "std_ttft_ms": 43454.8,
            "mean_tpot_ms": 123.0,
            "std_tpot_ms": 3.24,
            "mean_tps": 8.13,
            "std_tps": 0.21,
            "tps_decode_throughput": 260.2,
            "tps_prefill_throughput": 1224.6,
            "mean_e2el_ms": 216800.6,
            "request_throughput": 0.142,
            "total_input_tokens": 2048000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_13-28-47_isl-8000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_13-59-14",
            "model_name": "meta-llama/Llama-3.1-70B-Instruct",
            "model_id": "meta-llama/Llama-3.1-70B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 443664.6,
            "std_ttft_ms": 90599.45,
            "mean_tpot_ms": 149.0,
            "std_tpot_ms": 3.5,
            "mean_tps": 6.71,
            "std_tps": 0.15,
            "tps_decode_throughput": 214.8,
            "tps_prefill_throughput": 1154.0,
            "mean_e2el_ms": 453051.6,
            "request_throughput": 0.067,
            "total_input_tokens": 4096000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.1-70B-Instruct_t3k_2025-04-15_13-59-14_isl-16000_osl-64_maxcon-32_n-256.json"
        }
    ],
    "evals": [
        {
            "model": "Llama-3.1-70B-Instruct",
            "device": "t3k",
            "task_name": "meta_ifeval",
            "score": 86.27763223801736,
            "published_score": 87.5,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct#instruction-tuned-models",
            "gpu_reference_score": null,
            "gpu_reference_score_ref": null,
            "ratio_to_published": 0.9860300827201984,
            "ratio_to_reference": "N/A",
            "accuracy_check": false,
            "metadata": {
                "dataset_path": "parquet"
            }
        },
        {
            "model": "Llama-3.1-70B-Instruct",
            "device": "t3k",
            "task_name": "meta_gpqa_cot",
            "score": 49.107142857142854,
            "published_score": 46.7,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct#instruction-tuned-models",
            "gpu_reference_score": null,
            "gpu_reference_score_ref": null,
            "ratio_to_published": 1.0515448149281124,
            "ratio_to_reference": "N/A",
            "accuracy_check": false,
            "metadata": {
                "dataset_path": "meta-llama/Llama-3.1-70B-Instruct-evals"
            }
        }
    ]
}
