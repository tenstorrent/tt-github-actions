{
    "benchmarks": [
        {
            "timestamp": "2025-04-15_23-14-55",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 238.1,
            "std_ttft_ms": 2.94,
            "mean_tpot_ms": 22.6,
            "std_tpot_ms": 0.41,
            "mean_tps": 44.2,
            "std_tps": 0.78,
            "tps_decode_throughput": 44.2,
            "tps_prefill_throughput": 537.5,
            "mean_e2el_ms": 3111.7,
            "request_throughput": 0.321,
            "total_input_tokens": 1024,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-14-55_isl-128_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-15-37",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 1,
            "mean_ttft_ms": 338.5,
            "std_ttft_ms": 4.54,
            "mean_tpot_ms": 23.8,
            "std_tpot_ms": 0.22,
            "mean_tps": 42.09,
            "std_tps": 0.39,
            "tps_decode_throughput": 42.1,
            "tps_prefill_throughput": 378.2,
            "mean_e2el_ms": 24644.7,
            "request_throughput": 0.041,
            "total_input_tokens": 512,
            "total_output_tokens": 4096,
            "num_prompts": 4,
            "num_requests": 4,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-15-37_isl-128_osl-1024_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-04-15_23-17-46",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 1024,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 309.8,
            "std_ttft_ms": 113.82,
            "mean_tpot_ms": 24.5,
            "std_tpot_ms": 0.27,
            "mean_tps": 40.74,
            "std_tps": 0.45,
            "tps_decode_throughput": 40.7,
            "tps_prefill_throughput": 3305.9,
            "mean_e2el_ms": 3427.2,
            "request_throughput": 0.292,
            "total_input_tokens": 8192,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-17-46_isl-1024_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-18-23",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 395.0,
            "std_ttft_ms": 3.87,
            "mean_tpot_ms": 24.8,
            "std_tpot_ms": 0.2,
            "mean_tps": 40.29,
            "std_tps": 0.33,
            "tps_decode_throughput": 40.3,
            "tps_prefill_throughput": 5184.4,
            "mean_e2el_ms": 3547.4,
            "request_throughput": 0.282,
            "total_input_tokens": 16384,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-18-23_isl-2048_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-19-01",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3072,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 443.6,
            "std_ttft_ms": 118.9,
            "mean_tpot_ms": 25.2,
            "std_tpot_ms": 0.64,
            "mean_tps": 39.69,
            "std_tps": 0.99,
            "tps_decode_throughput": 39.7,
            "tps_prefill_throughput": 6925.1,
            "mean_e2el_ms": 3643.3,
            "request_throughput": 0.274,
            "total_input_tokens": 24576,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-19-01_isl-3072_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-19-40",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4096,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 640.8,
            "std_ttft_ms": 115.89,
            "mean_tpot_ms": 26.3,
            "std_tpot_ms": 0.48,
            "mean_tps": 38.03,
            "std_tps": 0.69,
            "tps_decode_throughput": 38.0,
            "tps_prefill_throughput": 6391.5,
            "mean_e2el_ms": 3980.5,
            "request_throughput": 0.251,
            "total_input_tokens": 32768,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-19-40_isl-4096_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-20-22",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8192,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 1012.2,
            "std_ttft_ms": 147.6,
            "mean_tpot_ms": 28.4,
            "std_tpot_ms": 0.55,
            "mean_tps": 35.19,
            "std_tps": 0.67,
            "tps_decode_throughput": 35.2,
            "tps_prefill_throughput": 8093.6,
            "mean_e2el_ms": 4621.0,
            "request_throughput": 0.216,
            "total_input_tokens": 65536,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-20-22_isl-8192_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-21-17",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16384,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 2117.1,
            "std_ttft_ms": 170.67,
            "mean_tpot_ms": 33.8,
            "std_tpot_ms": 0.28,
            "mean_tps": 29.57,
            "std_tps": 0.24,
            "tps_decode_throughput": 29.6,
            "tps_prefill_throughput": 7739.0,
            "mean_e2el_ms": 6411.9,
            "request_throughput": 0.156,
            "total_input_tokens": 131072,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-21-17_isl-16384_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-22-27",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 32000,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 4753.4,
            "std_ttft_ms": 166.08,
            "mean_tpot_ms": 43.7,
            "std_tpot_ms": 0.46,
            "mean_tps": 22.87,
            "std_tps": 0.24,
            "tps_decode_throughput": 22.9,
            "tps_prefill_throughput": 6732.1,
            "mean_e2el_ms": 10306.6,
            "request_throughput": 0.097,
            "total_input_tokens": 256000,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-22-27_isl-32000_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_23-24-13",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 32,
            "mean_ttft_ms": 5674.8,
            "std_ttft_ms": 89.7,
            "mean_tpot_ms": 25.5,
            "std_tpot_ms": 0.43,
            "mean_tps": 39.15,
            "std_tps": 0.65,
            "tps_decode_throughput": 1252.8,
            "tps_prefill_throughput": 721.8,
            "mean_e2el_ms": 8918.7,
            "request_throughput": 3.576,
            "total_input_tokens": 32768,
            "total_output_tokens": 32768,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-24-13_isl-128_osl-128_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_23-25-34",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 32,
            "mean_ttft_ms": 5714.0,
            "std_ttft_ms": 57.25,
            "mean_tpot_ms": 26.6,
            "std_tpot_ms": 0.16,
            "mean_tps": 37.61,
            "std_tps": 0.22,
            "tps_decode_throughput": 1203.6,
            "tps_prefill_throughput": 716.8,
            "mean_e2el_ms": 32912.2,
            "request_throughput": 0.971,
            "total_input_tokens": 16384,
            "total_output_tokens": 131072,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-25-34_isl-128_osl-1024_maxcon-32_n-128.json"
        },
        {
            "timestamp": "2025-04-15_23-28-16",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 32,
            "mean_ttft_ms": 10265.9,
            "std_ttft_ms": 1561.95,
            "mean_tpot_ms": 32.3,
            "std_tpot_ms": 11.54,
            "mean_tps": 31.0,
            "std_tps": 8.17,
            "tps_decode_throughput": 992.1,
            "tps_prefill_throughput": 6383.9,
            "mean_e2el_ms": 14362.3,
            "request_throughput": 2.222,
            "total_input_tokens": 524288,
            "total_output_tokens": 32768,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-28-16_isl-2048_osl-128_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_23-30-22",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 2048,
            "max_con": 32,
            "mean_ttft_ms": 10298.6,
            "std_ttft_ms": 1257.14,
            "mean_tpot_ms": 30.3,
            "std_tpot_ms": 0.81,
            "mean_tps": 32.98,
            "std_tps": 0.85,
            "tps_decode_throughput": 1055.2,
            "tps_prefill_throughput": 6363.6,
            "mean_e2el_ms": 72374.2,
            "request_throughput": 0.426,
            "total_input_tokens": 131072,
            "total_output_tokens": 131072,
            "num_prompts": 64,
            "num_requests": 64,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-30-22_isl-2048_osl-2048_maxcon-32_n-64.json"
        },
        {
            "timestamp": "2025-04-15_23-33-51",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 10311.3,
            "std_ttft_ms": 1772.84,
            "mean_tpot_ms": 37.9,
            "std_tpot_ms": 22.92,
            "mean_tps": 26.36,
            "std_tps": 9.93,
            "tps_decode_throughput": 843.7,
            "tps_prefill_throughput": 9310.2,
            "mean_e2el_ms": 12700.9,
            "request_throughput": 2.496,
            "total_input_tokens": 768000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-33-51_isl-3000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_23-35-42",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 15861.2,
            "std_ttft_ms": 3571.33,
            "mean_tpot_ms": 35.1,
            "std_tpot_ms": 31.35,
            "mean_tps": 28.46,
            "std_tps": 13.42,
            "tps_decode_throughput": 910.8,
            "tps_prefill_throughput": 8070.0,
            "mean_e2el_ms": 18074.7,
            "request_throughput": 1.709,
            "total_input_tokens": 1024000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-35-42_isl-4000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_23-38-21",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4500,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 16422.2,
            "std_ttft_ms": 6021.8,
            "mean_tpot_ms": 31.0,
            "std_tpot_ms": 1.21,
            "mean_tps": 32.25,
            "std_tps": 1.22,
            "tps_decode_throughput": 1032.1,
            "tps_prefill_throughput": 8768.6,
            "mean_e2el_ms": 18375.4,
            "request_throughput": 1.68,
            "total_input_tokens": 1152000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-38-21_isl-4500_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_23-41-04",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 27611.9,
            "std_ttft_ms": 5665.79,
            "mean_tpot_ms": 30.3,
            "std_tpot_ms": 0.58,
            "mean_tps": 32.99,
            "std_tps": 0.62,
            "tps_decode_throughput": 1055.6,
            "tps_prefill_throughput": 9271.4,
            "mean_e2el_ms": 29521.6,
            "request_throughput": 1.038,
            "total_input_tokens": 2048000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-41-04_isl-8000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_23-45-22",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "model_id": "meta-llama/Llama-3.2-3B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 63185.7,
            "std_ttft_ms": 12145.91,
            "mean_tpot_ms": 33.8,
            "std_tpot_ms": 0.77,
            "mean_tps": 29.57,
            "std_tps": 0.66,
            "tps_decode_throughput": 946.1,
            "tps_prefill_throughput": 8103.1,
            "mean_e2el_ms": 65316.5,
            "request_throughput": 0.465,
            "total_input_tokens": 4096000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-3B-Instruct_t3k_2025-04-15_23-45-22_isl-16000_osl-64_maxcon-32_n-256.json"
        }
    ],
    "evals": [
        {
            "model": "Llama-3.2-3B-Instruct",
            "device": "t3k",
            "task_name": "meta_gpqa",
            "score": 32.142857142857146,
            "published_score": 32.8,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct#instruction-tuned-models",
            "gpu_reference_score": 32.59,
            "gpu_reference_score_ref": "https://github.com/tenstorrent/tt-inference-server/issues/139#issuecomment-2761649617",
            "ratio_to_published": 0.9799651567944253,
            "ratio_to_reference": 0.986279752772542,
            "accuracy_check": true,
            "metadata": {
                "dataset_path": "meta-llama/Llama-3.2-3B-Instruct-evals"
            }
        },
        {
            "model": "Llama-3.2-3B-Instruct",
            "device": "t3k",
            "task_name": "meta_math",
            "score": 41.660000000000004,
            "published_score": 48.0,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct#instruction-tuned-models",
            "gpu_reference_score": 40.7,
            "gpu_reference_score_ref": "https://github.com/tenstorrent/tt-inference-server/issues/139#issuecomment-2761649617",
            "ratio_to_published": 0.8679166666666668,
            "ratio_to_reference": 1.0235872235872236,
            "accuracy_check": true,
            "metadata": {
                "dataset_path": "parquet"
            }
        }
    ]
}
