{
    "benchmarks": [
        {
            "timestamp": "2025-04-15_16-18-39",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 277.5,
            "std_ttft_ms": 15.59,
            "mean_tpot_ms": 39.7,
            "std_tpot_ms": 1.17,
            "mean_tps": 25.19,
            "std_tps": 0.72,
            "tps_decode_throughput": 25.2,
            "tps_prefill_throughput": 461.3,
            "mean_e2el_ms": 5319.0,
            "request_throughput": 0.188,
            "total_input_tokens": 1024,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-18-39_isl-128_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-19-40",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 1,
            "mean_ttft_ms": 432.7,
            "std_ttft_ms": 6.46,
            "mean_tpot_ms": 41.2,
            "std_tpot_ms": 0.41,
            "mean_tps": 24.3,
            "std_tps": 0.24,
            "tps_decode_throughput": 24.3,
            "tps_prefill_throughput": 295.8,
            "mean_e2el_ms": 42538.6,
            "request_throughput": 0.024,
            "total_input_tokens": 512,
            "total_output_tokens": 4096,
            "num_prompts": 4,
            "num_requests": 4,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-19-40_isl-128_osl-1024_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-04-15_16-23-17",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 1024,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 531.4,
            "std_ttft_ms": 114.47,
            "mean_tpot_ms": 41.6,
            "std_tpot_ms": 1.56,
            "mean_tps": 24.05,
            "std_tps": 0.87,
            "tps_decode_throughput": 24.1,
            "tps_prefill_throughput": 1926.9,
            "mean_e2el_ms": 5811.8,
            "request_throughput": 0.172,
            "total_input_tokens": 8192,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-23-17_isl-1024_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-24-15",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 896.2,
            "std_ttft_ms": 114.95,
            "mean_tpot_ms": 42.9,
            "std_tpot_ms": 1.83,
            "mean_tps": 23.29,
            "std_tps": 0.95,
            "tps_decode_throughput": 23.3,
            "tps_prefill_throughput": 2285.2,
            "mean_e2el_ms": 6349.9,
            "request_throughput": 0.157,
            "total_input_tokens": 16384,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-24-15_isl-2048_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-25-18",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3072,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 1002.7,
            "std_ttft_ms": 148.76,
            "mean_tpot_ms": 42.7,
            "std_tpot_ms": 1.86,
            "mean_tps": 23.4,
            "std_tps": 0.97,
            "tps_decode_throughput": 23.4,
            "tps_prefill_throughput": 3063.6,
            "mean_e2el_ms": 6431.1,
            "request_throughput": 0.155,
            "total_input_tokens": 24576,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-25-18_isl-3072_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-26-22",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4096,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 1456.7,
            "std_ttft_ms": 171.57,
            "mean_tpot_ms": 45.4,
            "std_tpot_ms": 1.37,
            "mean_tps": 22.03,
            "std_tps": 0.64,
            "tps_decode_throughput": 22.0,
            "tps_prefill_throughput": 2811.8,
            "mean_e2el_ms": 7221.4,
            "request_throughput": 0.138,
            "total_input_tokens": 32768,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-26-22_isl-4096_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-27-33",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8192,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 2469.5,
            "std_ttft_ms": 170.25,
            "mean_tpot_ms": 46.9,
            "std_tpot_ms": 2.04,
            "mean_tps": 21.34,
            "std_tps": 0.89,
            "tps_decode_throughput": 21.3,
            "tps_prefill_throughput": 3317.3,
            "mean_e2el_ms": 8419.6,
            "request_throughput": 0.119,
            "total_input_tokens": 65536,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-27-33_isl-8192_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-29-03",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16384,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 4704.3,
            "std_ttft_ms": 220.89,
            "mean_tpot_ms": 52.3,
            "std_tpot_ms": 1.71,
            "mean_tps": 19.11,
            "std_tps": 0.61,
            "tps_decode_throughput": 19.1,
            "tps_prefill_throughput": 3482.8,
            "mean_e2el_ms": 11349.5,
            "request_throughput": 0.088,
            "total_input_tokens": 131072,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-29-03_isl-16384_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-30-58",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 32000,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 10685.6,
            "std_ttft_ms": 539.54,
            "mean_tpot_ms": 64.6,
            "std_tpot_ms": 1.89,
            "mean_tps": 15.49,
            "std_tps": 0.44,
            "tps_decode_throughput": 15.5,
            "tps_prefill_throughput": 2994.7,
            "mean_e2el_ms": 18883.7,
            "request_throughput": 0.053,
            "total_input_tokens": 256000,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-30-58_isl-32000_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_16-34-01",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 16,
            "mean_ttft_ms": 2915.0,
            "std_ttft_ms": 213.22,
            "mean_tpot_ms": 47.4,
            "std_tpot_ms": 2.17,
            "mean_tps": 21.08,
            "std_tps": 0.92,
            "tps_decode_throughput": 337.3,
            "tps_prefill_throughput": 702.6,
            "mean_e2el_ms": 8938.4,
            "request_throughput": 1.787,
            "total_input_tokens": 16384,
            "total_output_tokens": 16384,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-34-01_isl-128_osl-128_maxcon-16_n-128.json"
        },
        {
            "timestamp": "2025-04-15_16-35-24",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 16,
            "mean_ttft_ms": 2938.3,
            "std_ttft_ms": 98.31,
            "mean_tpot_ms": 46.2,
            "std_tpot_ms": 2.75,
            "mean_tps": 21.64,
            "std_tps": 1.22,
            "tps_decode_throughput": 346.3,
            "tps_prefill_throughput": 697.0,
            "mean_e2el_ms": 50208.1,
            "request_throughput": 0.319,
            "total_input_tokens": 8192,
            "total_output_tokens": 65536,
            "num_prompts": 64,
            "num_requests": 64,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-35-24_isl-128_osl-1024_maxcon-16_n-64.json"
        },
        {
            "timestamp": "2025-04-15_16-39-34",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 16,
            "mean_ttft_ms": 11834.2,
            "std_ttft_ms": 330.16,
            "mean_tpot_ms": 46.7,
            "std_tpot_ms": 1.76,
            "mean_tps": 21.41,
            "std_tps": 0.78,
            "tps_decode_throughput": 342.6,
            "tps_prefill_throughput": 2768.9,
            "mean_e2el_ms": 17765.7,
            "request_throughput": 0.9,
            "total_input_tokens": 262144,
            "total_output_tokens": 16384,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-39-34_isl-2048_osl-128_maxcon-16_n-128.json"
        },
        {
            "timestamp": "2025-04-15_16-42-09",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 2048,
            "max_con": 16,
            "mean_ttft_ms": 11003.6,
            "std_ttft_ms": 65.76,
            "mean_tpot_ms": 48.0,
            "std_tpot_ms": 0.56,
            "mean_tps": 20.85,
            "std_tps": 0.24,
            "tps_decode_throughput": 333.5,
            "tps_prefill_throughput": 2977.9,
            "mean_e2el_ms": 109196.6,
            "request_throughput": 0.147,
            "total_input_tokens": 65536,
            "total_output_tokens": 65536,
            "num_prompts": 32,
            "num_requests": 32,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-42-09_isl-2048_osl-2048_maxcon-16_n-32.json"
        },
        {
            "timestamp": "2025-04-15_16-47-22",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3000,
            "output_sequence_length": 64,
            "max_con": 16,
            "mean_ttft_ms": 12461.2,
            "std_ttft_ms": 438.6,
            "mean_tpot_ms": 44.1,
            "std_tpot_ms": 1.61,
            "mean_tps": 22.67,
            "std_tps": 0.8,
            "tps_decode_throughput": 362.8,
            "tps_prefill_throughput": 3851.9,
            "mean_e2el_ms": 15239.9,
            "request_throughput": 1.049,
            "total_input_tokens": 384000,
            "total_output_tokens": 8192,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-47-22_isl-3000_osl-64_maxcon-16_n-128.json"
        },
        {
            "timestamp": "2025-04-15_16-49-34",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4000,
            "output_sequence_length": 64,
            "max_con": 16,
            "mean_ttft_ms": 19265.3,
            "std_ttft_ms": 602.91,
            "mean_tpot_ms": 48.9,
            "std_tpot_ms": 0.79,
            "mean_tps": 20.43,
            "std_tps": 0.33,
            "tps_decode_throughput": 326.9,
            "tps_prefill_throughput": 3322.0,
            "mean_e2el_ms": 22348.6,
            "request_throughput": 0.715,
            "total_input_tokens": 512000,
            "total_output_tokens": 8192,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-49-34_isl-4000_osl-64_maxcon-16_n-128.json"
        },
        {
            "timestamp": "2025-04-15_16-52-44",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4500,
            "output_sequence_length": 64,
            "max_con": 16,
            "mean_ttft_ms": 19594.7,
            "std_ttft_ms": 609.9,
            "mean_tpot_ms": 44.9,
            "std_tpot_ms": 0.91,
            "mean_tps": 22.29,
            "std_tps": 0.44,
            "tps_decode_throughput": 356.7,
            "tps_prefill_throughput": 3674.5,
            "mean_e2el_ms": 22420.8,
            "request_throughput": 0.713,
            "total_input_tokens": 576000,
            "total_output_tokens": 8192,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-52-44_isl-4500_osl-64_maxcon-16_n-128.json"
        },
        {
            "timestamp": "2025-04-15_16-55-55",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8000,
            "output_sequence_length": 64,
            "max_con": 16,
            "mean_ttft_ms": 32985.4,
            "std_ttft_ms": 8959.73,
            "mean_tpot_ms": 49.9,
            "std_tpot_ms": 3.32,
            "mean_tps": 20.04,
            "std_tps": 1.25,
            "tps_decode_throughput": 320.6,
            "tps_prefill_throughput": 3880.5,
            "mean_e2el_ms": 36129.9,
            "request_throughput": 0.428,
            "total_input_tokens": 1024000,
            "total_output_tokens": 8192,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_16-55-55_isl-8000_osl-64_maxcon-16_n-128.json"
        },
        {
            "timestamp": "2025-04-15_17-01-07",
            "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16000,
            "output_sequence_length": 64,
            "max_con": 16,
            "mean_ttft_ms": 70856.5,
            "std_ttft_ms": 17137.24,
            "mean_tpot_ms": 55.6,
            "std_tpot_ms": 2.83,
            "mean_tps": 17.99,
            "std_tps": 0.87,
            "tps_decode_throughput": 287.9,
            "tps_prefill_throughput": 3612.9,
            "mean_e2el_ms": 74357.6,
            "request_throughput": 0.206,
            "total_input_tokens": 2048000,
            "total_output_tokens": 8192,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-11B-Vision-Instruct_t3k_2025-04-15_17-01-07_isl-16000_osl-64_maxcon-16_n-128.json"
        }
    ],
    "evals": [
        {
            "model": "Llama-3.2-11B-Vision-Instruct",
            "device": "t3k",
            "task_name": "meta_gpqa",
            "score": 32.36607142857143,
            "published_score": 46.7,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct#instruction-tuned-models",
            "gpu_reference_score": null,
            "gpu_reference_score_ref": "",
            "ratio_to_published": 0.6930636280208015,
            "ratio_to_reference": "N/A",
            "accuracy_check": false,
            "metadata": {
                "dataset_path": "meta-llama/Llama-3.2-3B-Instruct-evals"
            }
        },
        {
            "model": "Llama-3.2-11B-Vision-Instruct",
            "device": "t3k",
            "task_name": "meta_math",
            "score": 44.62,
            "published_score": 68.0,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct#instruction-tuned-models",
            "gpu_reference_score": null,
            "gpu_reference_score_ref": "",
            "ratio_to_published": 0.6561764705882352,
            "ratio_to_reference": "N/A",
            "accuracy_check": false,
            "metadata": {
                "dataset_path": "parquet"
            }
        },
        {
            "model": "Llama-3.2-11B-Vision-Instruct",
            "device": "t3k",
            "task_name": "mmmu_val",
            "score": 43.333333333333336,
            "published_score": 50.7,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct#instruction-tuned-models",
            "gpu_reference_score": null,
            "gpu_reference_score_ref": "",
            "ratio_to_published": 0.8547008547008547,
            "ratio_to_reference": "N/A",
            "accuracy_check": false,
            "metadata": {
                "dataset_path": "MMMU/MMMU"
            }
        }
    ]
}
