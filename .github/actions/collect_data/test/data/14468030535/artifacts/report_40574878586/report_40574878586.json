{
    "benchmarks": [
        {
            "timestamp": "2025-04-15_22-43-31",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 163.7,
            "std_ttft_ms": 4.11,
            "mean_tpot_ms": 15.7,
            "std_tpot_ms": 0.18,
            "mean_tps": 63.84,
            "std_tps": 0.72,
            "tps_decode_throughput": 63.8,
            "tps_prefill_throughput": 782.0,
            "mean_e2el_ms": 2152.9,
            "request_throughput": 0.464,
            "total_input_tokens": 1024,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-43-31_isl-128_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-44-05",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 1,
            "mean_ttft_ms": 232.2,
            "std_ttft_ms": 5.34,
            "mean_tpot_ms": 15.9,
            "std_tpot_ms": 0.05,
            "mean_tps": 62.88,
            "std_tps": 0.2,
            "tps_decode_throughput": 62.9,
            "tps_prefill_throughput": 551.3,
            "mean_e2el_ms": 16502.2,
            "request_throughput": 0.061,
            "total_input_tokens": 512,
            "total_output_tokens": 4096,
            "num_prompts": 4,
            "num_requests": 4,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-44-05_isl-128_osl-1024_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-04-15_22-45-33",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 1024,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 216.3,
            "std_ttft_ms": 119.33,
            "mean_tpot_ms": 15.9,
            "std_tpot_ms": 0.21,
            "mean_tps": 62.71,
            "std_tps": 0.82,
            "tps_decode_throughput": 62.7,
            "tps_prefill_throughput": 4735.2,
            "mean_e2el_ms": 2241.6,
            "request_throughput": 0.446,
            "total_input_tokens": 8192,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-45-33_isl-1024_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-45-59",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 206.8,
            "std_ttft_ms": 3.19,
            "mean_tpot_ms": 16.3,
            "std_tpot_ms": 0.05,
            "mean_tps": 61.41,
            "std_tps": 0.19,
            "tps_decode_throughput": 61.4,
            "tps_prefill_throughput": 9902.0,
            "mean_e2el_ms": 2274.9,
            "request_throughput": 0.439,
            "total_input_tokens": 16384,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-45-59_isl-2048_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-46-26",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3072,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 257.8,
            "std_ttft_ms": 109.65,
            "mean_tpot_ms": 16.8,
            "std_tpot_ms": 0.1,
            "mean_tps": 59.5,
            "std_tps": 0.34,
            "tps_decode_throughput": 59.5,
            "tps_prefill_throughput": 11915.7,
            "mean_e2el_ms": 2392.4,
            "request_throughput": 0.418,
            "total_input_tokens": 24576,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-46-26_isl-3072_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-46-53",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4096,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 339.6,
            "std_ttft_ms": 114.05,
            "mean_tpot_ms": 17.2,
            "std_tpot_ms": 0.19,
            "mean_tps": 58.15,
            "std_tps": 0.62,
            "tps_decode_throughput": 58.1,
            "tps_prefill_throughput": 12059.6,
            "mean_e2el_ms": 2523.7,
            "request_throughput": 0.396,
            "total_input_tokens": 32768,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-46-53_isl-4096_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-47-22",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8192,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 575.4,
            "std_ttft_ms": 152.65,
            "mean_tpot_ms": 18.4,
            "std_tpot_ms": 0.45,
            "mean_tps": 54.3,
            "std_tps": 1.29,
            "tps_decode_throughput": 54.3,
            "tps_prefill_throughput": 14236.1,
            "mean_e2el_ms": 2914.4,
            "request_throughput": 0.343,
            "total_input_tokens": 65536,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-47-22_isl-8192_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-48-01",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16384,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 1135.5,
            "std_ttft_ms": 168.49,
            "mean_tpot_ms": 21.5,
            "std_tpot_ms": 0.12,
            "mean_tps": 46.46,
            "std_tps": 0.27,
            "tps_decode_throughput": 46.5,
            "tps_prefill_throughput": 14428.6,
            "mean_e2el_ms": 3868.9,
            "request_throughput": 0.258,
            "total_input_tokens": 131072,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-48-01_isl-16384_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-48-50",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 32000,
            "output_sequence_length": 128,
            "max_con": 1,
            "mean_ttft_ms": 2521.9,
            "std_ttft_ms": 176.12,
            "mean_tpot_ms": 26.3,
            "std_tpot_ms": 0.79,
            "mean_tps": 38.03,
            "std_tps": 1.1,
            "tps_decode_throughput": 38.0,
            "tps_prefill_throughput": 12688.6,
            "mean_e2el_ms": 5861.6,
            "request_throughput": 0.171,
            "total_input_tokens": 256000,
            "total_output_tokens": 1024,
            "num_prompts": 8,
            "num_requests": 8,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-48-50_isl-32000_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-04-15_22-49-56",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 128,
            "max_con": 32,
            "mean_ttft_ms": 3872.5,
            "std_ttft_ms": 162.48,
            "mean_tpot_ms": 17.0,
            "std_tpot_ms": 0.49,
            "mean_tps": 58.9,
            "std_tps": 1.66,
            "tps_decode_throughput": 1884.7,
            "tps_prefill_throughput": 1057.7,
            "mean_e2el_ms": 6028.9,
            "request_throughput": 5.282,
            "total_input_tokens": 32768,
            "total_output_tokens": 32768,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-49-56_isl-128_osl-128_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_22-50-52",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 128,
            "output_sequence_length": 1024,
            "max_con": 32,
            "mean_ttft_ms": 3823.3,
            "std_ttft_ms": 284.23,
            "mean_tpot_ms": 17.2,
            "std_tpot_ms": 0.17,
            "mean_tps": 58.04,
            "std_tps": 0.56,
            "tps_decode_throughput": 1857.2,
            "tps_prefill_throughput": 1071.3,
            "mean_e2el_ms": 21449.9,
            "request_throughput": 1.49,
            "total_input_tokens": 16384,
            "total_output_tokens": 131072,
            "num_prompts": 128,
            "num_requests": 128,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-50-52_isl-128_osl-1024_maxcon-32_n-128.json"
        },
        {
            "timestamp": "2025-04-15_22-52-40",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 128,
            "max_con": 32,
            "mean_ttft_ms": 5116.1,
            "std_ttft_ms": 1123.79,
            "mean_tpot_ms": 20.9,
            "std_tpot_ms": 7.11,
            "mean_tps": 47.94,
            "std_tps": 12.18,
            "tps_decode_throughput": 1534.0,
            "tps_prefill_throughput": 12809.6,
            "mean_e2el_ms": 7765.4,
            "request_throughput": 4.075,
            "total_input_tokens": 524288,
            "total_output_tokens": 32768,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-52-40_isl-2048_osl-128_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_22-53-52",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 2048,
            "output_sequence_length": 2048,
            "max_con": 32,
            "mean_ttft_ms": 4988.4,
            "std_ttft_ms": 821.83,
            "mean_tpot_ms": 19.3,
            "std_tpot_ms": 0.49,
            "mean_tps": 51.9,
            "std_tps": 1.3,
            "tps_decode_throughput": 1660.9,
            "tps_prefill_throughput": 13137.7,
            "mean_e2el_ms": 44427.4,
            "request_throughput": 0.693,
            "total_input_tokens": 131072,
            "total_output_tokens": 131072,
            "num_prompts": 64,
            "num_requests": 64,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-53-52_isl-2048_osl-2048_maxcon-32_n-64.json"
        },
        {
            "timestamp": "2025-04-15_22-56-04",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 3000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 5581.6,
            "std_ttft_ms": 856.32,
            "mean_tpot_ms": 19.9,
            "std_tpot_ms": 9.81,
            "mean_tps": 50.16,
            "std_tps": 16.54,
            "tps_decode_throughput": 1605.1,
            "tps_prefill_throughput": 17199.4,
            "mean_e2el_ms": 6837.6,
            "request_throughput": 4.626,
            "total_input_tokens": 768000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-56-04_isl-3000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_22-57-08",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 7205.7,
            "std_ttft_ms": 1525.39,
            "mean_tpot_ms": 29.8,
            "std_tpot_ms": 25.89,
            "mean_tps": 33.55,
            "std_tps": 15.6,
            "tps_decode_throughput": 1073.7,
            "tps_prefill_throughput": 17763.6,
            "mean_e2el_ms": 9083.3,
            "request_throughput": 3.411,
            "total_input_tokens": 1024000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-57-08_isl-4000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_22-58-32",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 4500,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 7803.5,
            "std_ttft_ms": 2942.51,
            "mean_tpot_ms": 19.2,
            "std_tpot_ms": 2.89,
            "mean_tps": 51.95,
            "std_tps": 6.78,
            "tps_decode_throughput": 1662.5,
            "tps_prefill_throughput": 18453.4,
            "mean_e2el_ms": 9016.1,
            "request_throughput": 3.417,
            "total_input_tokens": 1152000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-58-32_isl-4500_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_22-59-56",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 8000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 13667.7,
            "std_ttft_ms": 2779.1,
            "mean_tpot_ms": 19.3,
            "std_tpot_ms": 0.34,
            "mean_tps": 51.81,
            "std_tps": 0.89,
            "tps_decode_throughput": 1657.8,
            "tps_prefill_throughput": 18730.2,
            "mean_e2el_ms": 14883.8,
            "request_throughput": 2.054,
            "total_input_tokens": 2048000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_22-59-56_isl-8000_osl-64_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-04-15_23-02-12",
            "model_name": "meta-llama/Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": 16000,
            "output_sequence_length": 64,
            "max_con": 32,
            "mean_ttft_ms": 30752.0,
            "std_ttft_ms": 5668.13,
            "mean_tpot_ms": 21.7,
            "std_tpot_ms": 0.3,
            "mean_tps": 46.06,
            "std_tps": 0.62,
            "tps_decode_throughput": 1474.1,
            "tps_prefill_throughput": 16649.3,
            "mean_e2el_ms": 32119.7,
            "request_throughput": 0.945,
            "total_input_tokens": 4096000,
            "total_output_tokens": 16384,
            "num_prompts": 256,
            "num_requests": 256,
            "filename": "benchmark_Llama-3.2-1B-Instruct_t3k_2025-04-15_23-02-12_isl-16000_osl-64_maxcon-32_n-256.json"
        }
    ],
    "evals": [
        {
            "model": "Llama-3.2-1B-Instruct",
            "device": "t3k",
            "task_name": "meta_gpqa",
            "score": 28.794642857142854,
            "published_score": 27.2,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct#instruction-tuned-models",
            "gpu_reference_score": 27.01,
            "gpu_reference_score_ref": "https://github.com/tenstorrent/tt-inference-server/issues/139#issuecomment-2761649617",
            "ratio_to_published": 1.058626575630252,
            "ratio_to_reference": 1.0660734119638227,
            "accuracy_check": true,
            "metadata": {
                "dataset_path": "meta-llama/Llama-3.2-1B-Instruct-evals"
            }
        }
    ]
}
